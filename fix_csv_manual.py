"""
Parser manuel FINAL pour le CSV problÃ©matique
"""

import pandas as pd
import re
from pathlib import Path

def parse_csv_line(line):
    """
    Parse une ligne CSV avec guillemets complexes
    """
    # Retirer le guillemet de dÃ©but et de fin
    line = line.strip()
    if line.startswith('"') and line.endswith('"'):
        line = line[1:-1]
    
    # Parser manuellement en gÃ©rant les guillemets doubles
    values = []
    current_value = ""
    in_quotes = False
    i = 0
    
    while i < len(line):
        char = line[i]
        
        if char == '"':
            # VÃ©rifier si c'est un guillemet double ""
            if i + 1 < len(line) and line[i + 1] == '"':
                current_value += '"'
                i += 2
                continue
            else:
                # Toggle l'Ã©tat des guillemets
                in_quotes = not in_quotes
                i += 1
                continue
        
        if char == ',' and not in_quotes:
            # C'est un sÃ©parateur
            values.append(current_value)
            current_value = ""
            i += 1
            continue
        
        current_value += char
        i += 1
    
    # Ajouter la derniÃ¨re valeur
    if current_value or line.endswith(','):
        values.append(current_value)
    
    return values


def fix_csv_final(input_path, output_path):
    """
    Parse le CSV avec gestion des colonnes variables
    """
    print("="*70)
    print("ğŸ”§ PARSING FINAL DU CSV")
    print("="*70)
    
    print(f"\nğŸ“¥ Lecture de: {input_path}")
    
    with open(input_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    print(f"âœ… {len(lines)} lignes lues")
    
    # Parser le header
    print("\nğŸ” Parsing du header...")
    header = parse_csv_line(lines[0])
    n_cols = len(header)
    
    print(f"âœ… Header: {n_cols} colonnes")
    print(f"   Colonnes: {', '.join(header)}")
    
    # Analyser les lignes pour trouver le nombre de colonnes le plus frÃ©quent
    print(f"\nğŸ” Analyse de la structure...")
    col_counts = {}
    sample_size = min(1000, len(lines) - 1)
    
    for line in lines[1:sample_size+1]:
        values = parse_csv_line(line)
        n = len(values)
        col_counts[n] = col_counts.get(n, 0) + 1
    
    print(f"   Distribution des colonnes (sur {sample_size} lignes):")
    for n, count in sorted(col_counts.items()):
        print(f"   - {n} colonnes: {count} lignes ({count/sample_size*100:.1f}%)")
    
    # Utiliser le nombre de colonnes le plus frÃ©quent
    most_common_cols = max(col_counts.items(), key=lambda x: x[1])[0]
    
    if most_common_cols != n_cols:
        print(f"\nâš ï¸  Le header a {n_cols} colonnes, mais la majoritÃ© des lignes en ont {most_common_cols}")
        
        if most_common_cols > n_cols:
            # Ajouter des colonnes supplÃ©mentaires
            for i in range(n_cols, most_common_cols):
                header.append(f"Extra_Column_{i-n_cols+1}")
            print(f"   â†’ Ajout de {most_common_cols - n_cols} colonnes supplÃ©mentaires")
        
        n_cols = most_common_cols
    
    # Parser toutes les lignes avec le bon nombre de colonnes
    print(f"\nğŸ”„ Parsing avec {n_cols} colonnes attendues...")
    data_rows = []
    skipped = 0
    
    for i, line in enumerate(lines[1:], start=1):
        if i % 10000 == 0:
            print(f"   â³ {i:,} lignes parsÃ©es... ({len(data_rows):,} valides)")
        
        try:
            values = parse_csv_line(line)
            
            if len(values) == n_cols:
                data_rows.append(values)
            elif len(values) < n_cols:
                # ComplÃ©ter avec des valeurs vides
                values.extend([''] * (n_cols - len(values)))
                data_rows.append(values)
            else:
                # Trop de colonnes - probablement une virgule dans un champ
                # Garder les n_cols premiÃ¨res colonnes
                data_rows.append(values[:n_cols])
                
        except Exception as e:
            skipped += 1
            if skipped <= 5:
                print(f"   âŒ Ligne {i}: {str(e)[:50]}")
    
    print(f"\nâœ… Parsing terminÃ©:")
    print(f"   - Lignes valides: {len(data_rows):,}")
    print(f"   - Lignes problÃ©matiques: {skipped:,}")
    
    # CrÃ©er le DataFrame
    print(f"\nğŸ“Š CrÃ©ation du DataFrame...")
    df = pd.DataFrame(data_rows, columns=header)
    
    print(f"âœ… DataFrame crÃ©Ã©: {df.shape}")
    
    # NE PAS tout convertir en numÃ©rique - garder les types appropriÃ©s
    print(f"\nğŸ”„ DÃ©tection des types de colonnes...")
    
    numeric_cols = []
    text_cols = []
    
    for col in df.columns:
        # Essayer de convertir en numÃ©rique
        try:
            converted = pd.to_numeric(df[col], errors='coerce')
            
            # Si plus de 80% des valeurs sont converties, c'est numÃ©rique
            if converted.notna().sum() / len(df) > 0.8:
                df[col] = converted
                numeric_cols.append(col)
            else:
                # Garder comme texte
                text_cols.append(col)
        except:
            text_cols.append(col)
    
    print(f"âœ… Types dÃ©tectÃ©s:")
    print(f"   - Colonnes numÃ©riques: {len(numeric_cols)}")
    print(f"   - Colonnes textuelles: {len(text_cols)}")
    
    if numeric_cols:
        print(f"\nğŸ”¢ Colonnes numÃ©riques:")
        for col in numeric_cols:
            non_null = df[col].notna().sum()
            print(f"   â€¢ {col:30} ({non_null:,} valeurs)")
    
    if text_cols:
        print(f"\nğŸ“ Colonnes textuelles:")
        for col in text_cols[:10]:  # Afficher les 10 premiÃ¨res
            unique = df[col].nunique()
            print(f"   â€¢ {col:30} ({unique:,} valeurs uniques)")
    
    # Sauvegarder
    if output_path:
        df.to_csv(output_path, index=False, encoding='utf-8')
        print(f"\nğŸ’¾ SauvegardÃ©: {output_path}")
    
    # AperÃ§u
    print(f"\nğŸ“Š AperÃ§u des premiÃ¨res lignes:")
    print(df.head())
    
    print(f"\nğŸ“Š Info complÃ¨te:")
    print(df.info())
    
    return df


def create_optimized_training_script(df):
    """
    CrÃ©e un script d'entraÃ®nement avec les bonnes colonnes
    """
    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
    text_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    # Trouver la target
    target_candidates = ['Profit', 'Sales', 'Revenue']
    target = None
    
    for candidate in target_candidates:
        if candidate in numeric_cols:
            target = candidate
            break
    
    if target is None and numeric_cols:
        target = numeric_cols[0]
    
    features = [col for col in numeric_cols if col != target]
    
    code = f'''"""
Script d'entraÃ®nement - Global Superstore
GÃ©nÃ©rÃ© automatiquement
"""

import pandas as pd
import joblib
import os
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, VotingRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

os.makedirs("models", exist_ok=True)

print("="*70)
print("ğŸš€ ENTRAÃNEMENT - GLOBAL SUPERSTORE")
print("="*70)

# Charger les donnÃ©es
print("\\nğŸ“¥ Chargement...")
df = pd.read_csv("data/Global_Superstore_FIXED.csv")
print(f"âœ… {{df.shape[0]:,}} lignes Ã— {{df.shape[1]}} colonnes")

# Configuration
TARGET = '{target}'
FEATURES = {features}

print(f"\\nğŸ¯ Configuration:")
print(f"   Target: {{TARGET}}")
print(f"   Features: {{len(FEATURES)}}")

# PrÃ©parer les donnÃ©es
X = df[FEATURES].copy()
y = df[TARGET].copy()

# Nettoyer
print(f"\\nğŸ” Nettoyage...")
if X.isnull().sum().sum() > 0:
    print(f"   Remplissage de {{X.isnull().sum().sum()}} valeurs manquantes")
    X = X.fillna(X.median())

if y.isnull().sum() > 0:
    print(f"   Suppression de {{y.isnull().sum()}} lignes avec target manquante")
    valid_idx = y.notna()
    X = X[valid_idx]
    y = y[valid_idx]

print(f"âœ… {{len(X):,}} lignes valides")

# Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"\\nğŸ“Š Split: {{X_train.shape[0]:,}} train / {{X_test.shape[0]:,}} test")

# EntraÃ®nement
print(f"\\nğŸ‹ï¸ EntraÃ®nement...")
models = {{}}

# Linear Regression
try:
    print("\\n1ï¸âƒ£ Linear Regression")
    lr = LinearRegression()
    lr.fit(X_train, y_train)
    print(f"   Train RÂ²: {{lr.score(X_train, y_train):.4f}}")
    print(f"   Test RÂ²:  {{lr.score(X_test, y_test):.4f}}")
    joblib.dump(lr, 'models/linear_regression_final.pkl')
    models['Linear Regression'] = lr
except Exception as e:
    print(f"   âŒ {{str(e)[:80]}}")

# Random Forest
try:
    print("\\n2ï¸âƒ£ Random Forest")
    rf = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)
    rf.fit(X_train, y_train)
    print(f"   Train RÂ²: {{rf.score(X_train, y_train):.4f}}")
    print(f"   Test RÂ²:  {{rf.score(X_test, y_test):.4f}}")
    joblib.dump(rf, 'models/random_forest_champion_model.pkl')
    models['Random Forest'] = rf
except Exception as e:
    print(f"   âŒ {{str(e)[:80]}}")

# Gradient Boosting
try:
    print("\\n3ï¸âƒ£ Gradient Boosting")
    gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
    gb.fit(X_train, y_train)
    print(f"   Train RÂ²: {{gb.score(X_train, y_train):.4f}}")
    print(f"   Test RÂ²:  {{gb.score(X_test, y_test):.4f}}")
    joblib.dump(gb, 'models/gradient_boosting_champion_model.pkl')
    models['Gradient Boosting'] = gb
except Exception as e:
    print(f"   âŒ {{str(e)[:80]}}")

# Voting Regressor
try:
    print("\\n4ï¸âƒ£ Voting Regressor")
    voting = VotingRegressor([
        ('lr', LinearRegression()),
        ('rf', RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)),
        ('gb', GradientBoostingRegressor(n_estimators=50, random_state=42))
    ])
    voting.fit(X_train, y_train)
    print(f"   Train RÂ²: {{voting.score(X_train, y_train):.4f}}")
    print(f"   Test RÂ²:  {{voting.score(X_test, y_test):.4f}}")
    joblib.dump(voting, 'models/VOTING_REGRESSOR_FINAL_CHAMPION.pkl')
    models['Voting Regressor'] = voting
except Exception as e:
    print(f"   âŒ {{str(e)[:80]}}")

# Ã‰valuation
print(f"\\n" + "="*70)
print("ğŸ“Š Ã‰VALUATION FINALE")
print("="*70)

results = []
for name, model in models.items():
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    
    results.append({{'ModÃ¨le': name, 'RÂ²': r2, 'RMSE': rmse, 'MAE': mae}})
    print(f"\\n{{name:25}} RÂ²: {{r2:.4f}}  RMSE: {{rmse:.2f}}  MAE: {{mae:.2f}}")

results_df = pd.DataFrame(results).sort_values('RÂ²', ascending=False)
results_df.to_csv('models/evaluation_results.csv', index=False)

print(f"\\n" + "="*70)
print("âœ… TERMINÃ‰!")
print(f"ğŸ† Champion: {{results_df.iloc[0]['ModÃ¨le']}} (RÂ² = {{results_df.iloc[0]['RÂ²']:.4f}})")
print(f"ğŸ“¦ {{len(models)}} modÃ¨les dans models/")
print("="*70)
'''
    
    return code


if __name__ == "__main__":
    csv_path = "data/Global_Superstore_100%_PROPRE_51290.csv"
    output_path = "data/Global_Superstore_FIXED.csv"
    
    if not Path(csv_path).exists():
        print(f"âŒ Fichier non trouvÃ©: {csv_path}")
        exit(1)
    
    try:
        df = fix_csv_final(csv_path, output_path)
        
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
        
        if len(numeric_cols) >= 5:
            print("\n" + "="*70)
            print("ğŸ‰ SUCCÃˆS COMPLET!")
            print("="*70)
            
            # GÃ©nÃ©rer le script d'entraÃ®nement
            training_code = create_optimized_training_script(df)
            
            with open("train_models.py", "w", encoding='utf-8') as f:
                f.write(training_code)
            
            print(f"""
âœ… CSV corrigÃ©: {{df.shape[0]:,}} lignes Ã— {{df.shape[1]}} colonnes
âœ… {{len(numeric_cols)}} colonnes numÃ©riques
âœ… Script gÃ©nÃ©rÃ©: train_models.py

ğŸ“‹ PROCHAINES Ã‰TAPES:

1ï¸âƒ£ Le CSV est prÃªt: data/Global_Superstore_FIXED.csv

2ï¸âƒ£ EntraÃ®nez les modÃ¨les:
   python train_models.py

3ï¸âƒ£ Lancez Streamlit:
   streamlit run app.py

ğŸ¯ Colonnes numÃ©riques: {{', '.join(numeric_cols[:5])}}...
            """)
        else:
            print(f"\\nâš ï¸  Seulement {{len(numeric_cols)}} colonnes numÃ©riques")
            print("Les modÃ¨les ML nÃ©cessitent plus de features numÃ©riques.")
    
    except Exception as e:
        print(f"\\nâŒ ERREUR: {{e}}")
        import traceback
        traceback.print_exc()